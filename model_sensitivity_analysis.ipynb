{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf29868",
   "metadata": {},
   "source": [
    "# Model Sensitivity Analysis for Fraud Detection Pipeline\n",
    "\n",
    "This notebook helps you analyze and improve the sensitivity of your fraud detection model pipeline. It loads the existing model, evaluates its predictions on sample inputs, analyzes feature importances, and explores retraining and more complex models to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ea1a3",
   "metadata": {},
   "source": [
    "## 1. Load the Existing Model Pipeline\n",
    "\n",
    "Load the trained model pipeline from `models/dbt_fraud_detection_pipeline.pkl` using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Path to the trained model pipeline\n",
    "model_path = os.path.join('models', 'dbt_fraud_detection_pipeline.pkl')\n",
    "model = joblib.load(model_path)\n",
    "print(f\"Loaded model pipeline from: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13814231",
   "metadata": {},
   "source": [
    "## 2. Evaluate Model Sensitivity on Sample Inputs\n",
    "\n",
    "Load sample JSON files from `test_samples/` and use the model pipeline to predict outputs. Compare predictions for different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051079b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Find all sample JSON files in test_samples/\n",
    "sample_files = glob.glob('test_samples/*.json')\n",
    "print(f\"Found sample files: {sample_files}\")\n",
    "\n",
    "# Predict for each sample and show results\n",
    "for file in sample_files:\n",
    "    with open(file, 'r') as f:\n",
    "        sample = json.load(f)\n",
    "    df = pd.DataFrame([sample])\n",
    "    pred = model.predict(df)[0]\n",
    "    prob = model.predict_proba(df)[0]\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"Prediction: {pred}, Probabilities: {prob}\")\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcac614",
   "metadata": {},
   "source": [
    "## 3. Analyze Feature Importances\n",
    "\n",
    "Extract and visualize feature importances from the trained model (if supported, e.g., tree-based models or logistic regression coefficients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Try to extract feature importances from the classifier\n",
    "clf = model.named_steps.get('classifier', None)\n",
    "preprocessor = model.named_steps.get('preprocessor', None)\n",
    "\n",
    "if clf is not None and hasattr(clf, 'feature_importances_'):\n",
    "    # Get feature names after preprocessing\n",
    "    if preprocessor is not None:\n",
    "        try:\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "        except Exception:\n",
    "            feature_names = [f'feature_{i}' for i in range(len(clf.feature_importances_))]\n",
    "    else:\n",
    "        feature_names = [f'feature_{i}' for i in range(len(clf.feature_importances_))]\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.bar(range(len(importances)), importances[indices])\n",
    "    plt.xticks(range(len(importances)), np.array(feature_names)[indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Feature importances not available for this classifier.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f39f1",
   "metadata": {},
   "source": [
    "## 4. Retrain Model with Additional Data or Features\n",
    "\n",
    "Augment the training dataset with more data or engineer new features. Retrain the model pipeline and save the updated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load additional data or engineer new features here\n",
    "# df_new = ... # Load or create new data\n",
    "# df_augmented = pd.concat([df, df_new], ignore_index=True)\n",
    "#\n",
    "# Optionally, engineer new features\n",
    "# df_augmented['new_feature'] = ...\n",
    "#\n",
    "# Retrain the pipeline (replace X_train, y_train with your new data)\n",
    "# model_pipeline.fit(X_train, y_train)\n",
    "# joblib.dump(model_pipeline, 'models/dbt_fraud_detection_pipeline_updated.pkl')\n",
    "\n",
    "print(\"Fill in this cell with your data augmentation and retraining steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952b160",
   "metadata": {},
   "source": [
    "## 5. Experiment with More Complex Models\n",
    "\n",
    "Replace the current estimator in the pipeline with a more complex model (e.g., RandomForest, XGBoost). Train and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assume you have X_train, y_train from your original or augmented data\n",
    "# Replace the classifier in the pipeline with RandomForest\n",
    "if 'classifier' in model.named_steps:\n",
    "    steps = list(model.named_steps.items())\n",
    "    steps = [(name, step) if name != 'classifier' else ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)) for name, step in steps]\n",
    "    rf_pipeline = Pipeline(steps)\n",
    "    # rf_pipeline.fit(X_train, y_train)\n",
    "    print(\"RandomForestClassifier added to pipeline. Uncomment fit() and provide data to train.\")\n",
    "else:\n",
    "    print(\"No 'classifier' step found in the pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a462f",
   "metadata": {},
   "source": [
    "## 6. Compare Prediction Outputs for Different Samples\n",
    "\n",
    "Run predictions on the same test samples using the updated model(s) and compare the outputs to assess improvements in sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ca351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare predictions from the updated model(s) on the same test samples\n",
    "# for file in sample_files:\n",
    "#     with open(file, 'r') as f:\n",
    "#         sample = json.load(f)\n",
    "#     df = pd.DataFrame([sample])\n",
    "#     pred = rf_pipeline.predict(df)[0]\n",
    "#     prob = rf_pipeline.predict_proba(df)[0]\n",
    "#     print(f\"File: {file}\")\n",
    "#     print(f\"RandomForest Prediction: {pred}, Probabilities: {prob}\")\n",
    "#     print('-' * 40)\n",
    "\n",
    "print(\"Fill in this cell to compare predictions from your updated model(s) on the test samples.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
